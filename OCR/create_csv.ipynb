{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50897da5-58d4-4db3-ab12-daa3021b674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df = pd.read_excel('../pilot_data_ocr.xlsx', engine='openpyxl')\n",
    "commonkaha = ['は', 'か', 'へ', 'で', 'す', 'あ', 'お',\n",
    "              'の', 'に', 'を', 'る', 'く', 'し', 'な', 'よ', 'ス', 'ル']\n",
    "commonkanji = ['日', '事', '人', '本', '大', '上', '生','文','明',\n",
    "               '情', '国', '子', '用', '战', '手', '小','年']\n",
    "kaha_sets = {char: set() for char in commonkaha}\n",
    "kanji_sets = {char: set() for char in commonkanji}\n",
    "for i in range(len(df)):\n",
    "    group = df.iloc[i].group\n",
    "    first = df.iloc[i].ocr\n",
    "    filename = df.iloc[i].filename\n",
    "    if first in commonkaha:\n",
    "        kaha_sets[first].add(group +\"/\"+filename)\n",
    "    # Check if the first character is in commonkanji\n",
    "    elif first in commonkanji:\n",
    "        kanji_sets[first].add(group+\"/\"+filename)\n",
    "\n",
    "#は: {'B/B_3_47.jpg', 'D/D_4_5.jpg', 'B/B_5_17.jpg', 'Grant/25.jpg', 'C/C_4_15.jpg', 'B/B_3_1.jpg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8692fc78-e124-45e9-bc47-fafd14e5c68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 CSV files have been created.\n"
     ]
    }
   ],
   "source": [
    "directory = 'cluster'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "count_csv = 0\n",
    "# Iterate through each key-value pair in the dictionary and create a CSV file\n",
    "for key, images in kaha_sets.items():\n",
    "    # Convert the set of images to a list and then to a DataFrame\n",
    "    df = pd.DataFrame(list(images), columns=['Image_name'])\n",
    "    \n",
    "    # Define the path with the directory and file name\n",
    "    file_path = os.path.join(directory, f'{key}.csv')\n",
    "    \n",
    "    # Save the DataFrame to a CSV file, naming the file using the key\n",
    "    df.to_csv(file_path, index=False)\n",
    "    count_csv += 1\n",
    "    \n",
    "for key, images in kanji_sets.items():\n",
    "    # Convert the set of images to a list and then to a DataFrame\n",
    "    df = pd.DataFrame(list(images), columns=['Image_name'])\n",
    "    \n",
    "    # Define the path with the directory and file name\n",
    "    file_path = os.path.join(directory, f'{key}.csv')\n",
    "    \n",
    "    # Save the DataFrame to a CSV file, naming the file using the key\n",
    "    df.to_csv(file_path, index=False)\n",
    "    count_csv += 1\n",
    "print(f\"{count_csv} CSV files have been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14524d7b-ecb5-4ad6-bc08-372bfd286f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def clean_csv_files(directory):\n",
    "    # Define the markers to look for\n",
    "    markers = [\"<<<<<\", \"=====\", \">>>>>\"]\n",
    "    \n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file is a CSV\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            \n",
    "            # Read the file\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "            # Separate the header (first line)\n",
    "            header = lines[0]\n",
    "            data_lines = lines[1:]\n",
    "\n",
    "            # Remove lines containing markers and eliminate duplicates using a set\n",
    "            cleaned_lines = set(line for line in data_lines if not any(marker in line for marker in markers))\n",
    "\n",
    "            # Write the header and cleaned, unique data lines back to the same file\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(header)  # Write the header first\n",
    "                file.writelines(sorted(cleaned_lines))  # Sorting optional, to maintain consistent order\n",
    "\n",
    "# Example usage\n",
    "directory_path = 'cluster'  # Replace with the path to your directory containing CSV files\n",
    "clean_csv_files(directory_path)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a9267-8bac-41ba-9c6c-6b7b9df775e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
