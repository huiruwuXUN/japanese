{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cep0pflk6vVO",
        "outputId": "3919c442-c87e-4ad7-c9df-d4e317f9ff2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Connected_components_PyTorch'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 30 (delta 7), reused 23 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (30/30), 132.96 KiB | 7.82 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n",
            "/content/Connected_components_PyTorch\n",
            "Obtaining file:///content/Connected_components_PyTorch\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: cc_torch\n",
            "  Running setup.py develop for cc_torch\n",
            "Successfully installed cc_torch-0.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!git clone https://github.com/zsef123/Connected_components_PyTorch.git\n",
        "%cd Connected_components_PyTorch\n",
        "!pip install -e .\n",
        "\n",
        "!pip install -q opencv-python matplotlib\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0Z4vBFV5csa"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sy_RyijV63XZ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from cc_torch import connected_components\n",
        "from google.colab import files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRl9B_sj7Dki",
        "outputId": "de49c90b-61d8-413b-c8c3-f81743af0c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "\n",
        "img_path = \"/content/drive/MyDrive/img/p1/RC04844/page_1.png\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6k5a_ldL7NX1"
      },
      "outputs": [],
      "source": [
        "gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\n",
        "upscaled = cv2.resize(gray, None, fx=8, fy=8, interpolation=cv2.INTER_LANCZOS4)\n",
        "clahe = cv2.createCLAHE(clipLimit=0.1, tileGridSize=(4,4))\n",
        "enhanced = clahe.apply(upscaled)\n",
        "\n",
        "\n",
        "def phansalkar_threshold(image, window_size=31, k=0.2, R=128, p=20, q=6.2):\n",
        "    image = image.astype(np.float32)\n",
        "    mean = cv2.boxFilter(image, ddepth=-1, ksize=(window_size, window_size))\n",
        "    sqmean = cv2.sqrBoxFilter(image, ddepth=-1, ksize=(window_size, window_size))\n",
        "    stddev = np.sqrt(np.maximum(sqmean - mean**2, 1e-4))\n",
        "    threshold = mean * (1 + p * np.exp(-q * mean / 255) + k * ((stddev / R) - 1))\n",
        "    binary = (image > threshold).astype(np.uint8)\n",
        "    return binary\n",
        "\n",
        "binary = phansalkar_threshold(enhanced)\n",
        "\n",
        "def remove_speckle(binary_np, kernel_size=5, iterations=2):\n",
        "    inv = cv2.bitwise_not(binary_np * 255)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
        "    opened = cv2.morphologyEx(inv, cv2.MORPH_OPEN, kernel, iterations=iterations)\n",
        "    return (cv2.bitwise_not(opened) > 128).astype(np.uint8)\n",
        "\n",
        "binary_clean = remove_speckle(binary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GsPOv0BEbgY"
      },
      "outputs": [],
      "source": [
        "# Visualize intermediate binary_clean\n",
        "#cv2.imwrite(\"binary_clean.png\", binary_clean * 255)\n",
        "#files.download(\"binary_clean.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "JA0M6RTcJ8EA",
        "outputId": "323c54c8-8803-4e1b-de0a-17a66a083580"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_474c834f-f5b2-497f-b9bd-51b22edffa15\", \"final.png\", 378824)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "binary = binary_clean * 255\n",
        "final = cv2.resize(binary, (gray.shape[1], gray.shape[0]), interpolation=cv2.INTER_AREA)\n",
        "cv2.imwrite(\"final.png\", final)\n",
        "files.download(\"final.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✅ Step 6: GPU-accelerated connected components\n",
        "tensor = torch.tensor(binary_clean).to(device, dtype=torch.uint8) # Changed shape here\n",
        "print(\"Shape of tensor:\", tensor.shape)\n",
        "labels = connected_components_labeling(tensor) # shape: [H, W]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from cc_torch import connected_components_labeling\n",
        "\n",
        "def _pad_to_even_2d(t: torch.Tensor, pad_value: int = 0, mode: str = \"constant\"):\n",
        "    assert t.ndim in (2, 3)\n",
        "    if t.ndim == 2:\n",
        "        H, W = t.shape\n",
        "        pad = (0, W % 2, 0, H % 2)\n",
        "        if pad == (0,0,0,0):\n",
        "            return t, (slice(0,H), slice(0,W))\n",
        "        tp = F.pad(t[None, None], pad, mode=mode, value=pad_value).squeeze(0).squeeze(0)\n",
        "        return tp, (slice(0,H), slice(0,W))\n",
        "    else:\n",
        "        H, W, C = t.shape\n",
        "        pad = (0, W % 2, 0, H % 2)\n",
        "        if pad == (0,0,0,0):\n",
        "            return t, (slice(0,H), slice(0,W), slice(0,C))\n",
        "        tp = F.pad(t.permute(2,0,1)[None], pad, mode=mode, value=pad_value).squeeze(0).permute(1,2,0)\n",
        "        return tp, (slice(0,H), slice(0,W), slice(0,C))\n",
        "\n",
        "def _dilate(mask: torch.Tensor, iters: int) -> torch.Tensor:\n",
        "    \"\"\"Binary dilation using max-pool; mask is [H,W] bool/uint8 on GPU.\"\"\"\n",
        "    if iters <= 0:\n",
        "        return mask\n",
        "    x = mask.float()[None, None]  # [1,1,H,W]\n",
        "    for _ in range(iters):\n",
        "        x = (F.max_pool2d(x, kernel_size=3, stride=1, padding=1) > 0).float()\n",
        "    return (x[0,0] > 0)\n",
        "\n",
        "def apply_regions_to_original_no_blend_with_halo(\n",
        "    original_img_np: np.ndarray,   # uint8, [H,W] or [H,W,3]\n",
        "    binary_np_img: np.ndarray,     # uint8 {0,1}, [H,W]\n",
        "    min_area_black: int = 30,      # remove tiny black speckles\n",
        "    min_area_white: int = 30,      # fill tiny white holes\n",
        "    fg_val: int = 0,               # black for grayscale\n",
        "    bg_val: int = 255,             # white for grayscale\n",
        "    speckle_expand_iters: int = 1, # grow radius in pixels around speckle\n",
        "    speckle_expand_gray_thresh: int | None = 210  # e.g., 200–220; None = no gating\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Detect on binary; apply on original.\n",
        "    Black speckles: set speckle + (optional light-gray halo) to white.\n",
        "    White holes: set small 1-components to black.\n",
        "    Everything else unchanged.\n",
        "    \"\"\"\n",
        "    assert binary_np_img.ndim == 2\n",
        "    assert set(np.unique(binary_np_img)).issubset({0,1})\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    if device.type != 'cuda':\n",
        "        raise RuntimeError(\"cc_torch build requires CUDA. Enable GPU or use a CPU CCL fallback.\")\n",
        "\n",
        "    # tensors\n",
        "    bin_t = torch.from_numpy(binary_np_img.astype(np.uint8)).to(device)\n",
        "    if original_img_np.ndim == 2:\n",
        "        orig_t = torch.from_numpy(original_img_np).to(device)           # [H,W]\n",
        "        is_color = False\n",
        "    else:\n",
        "        orig_t = torch.from_numpy(original_img_np).to(device)           # [H,W,3]\n",
        "        is_color = True\n",
        "\n",
        "    # pad once\n",
        "    bin_pad, _ = _pad_to_even_2d(bin_t, pad_value=0, mode=\"constant\")\n",
        "    orig_pad, unpad_img = _pad_to_even_2d(orig_t, pad_value=0, mode=\"replicate\")\n",
        "    H, W = bin_pad.shape[:2]\n",
        "    assert (H, W) == orig_pad.shape[:2]\n",
        "\n",
        "    # -------- Pass 1: remove black speckles (+ optional halo)\n",
        "    inv = (1 - bin_pad)  # speckles -> 1\n",
        "    labels_black = connected_components_labeling(inv).to(device)\n",
        "\n",
        "    for lid in torch.unique(labels_black):\n",
        "        if lid.item() == 0:\n",
        "            continue\n",
        "        region = (labels_black == lid)\n",
        "        if int(region.sum().item()) >= min_area_black:\n",
        "            continue\n",
        "\n",
        "        # expand region by N iters\n",
        "        expanded = _dilate(region, speckle_expand_iters)\n",
        "\n",
        "        # optionally gate expansion by original gray level (light-gray only)\n",
        "        if speckle_expand_gray_thresh is not None:\n",
        "            if is_color:\n",
        "                # use luminance approximation to gate\n",
        "                # convert BGR/RGB ambiguity not critical for thresholding halo.\n",
        "                y = (0.299*orig_pad[...,0] + 0.587*orig_pad[...,1] + 0.114*orig_pad[...,2]).to(orig_pad.dtype)\n",
        "                gate = (1 <= speckle_expand_gray_thresh)\n",
        "            else:\n",
        "                gate = (1 <= speckle_expand_gray_thresh)\n",
        "            expanded = expanded & gate\n",
        "\n",
        "        # always include the original speckle core\n",
        "        expanded = expanded | region\n",
        "\n",
        "        # set expanded area to background white\n",
        "        if is_color:\n",
        "            orig_pad[..., 0][expanded] = bg_val\n",
        "            orig_pad[..., 1][expanded] = bg_val\n",
        "            orig_pad[..., 2][expanded] = bg_val\n",
        "        else:\n",
        "            orig_pad[expanded] = bg_val\n",
        "\n",
        "    # -------- Pass 2: fill white holes (no expansion)\n",
        "    labels_white = connected_components_labeling(bin_pad).to(device)\n",
        "    for lid in torch.unique(labels_white):\n",
        "        if lid.item() == 0:\n",
        "            continue\n",
        "        region = (labels_white == lid)\n",
        "        if int(region.sum().item()) < min_area_white:\n",
        "            if is_color:\n",
        "                orig_pad[..., 0][region] = fg_val\n",
        "                orig_pad[..., 1][region] = fg_val\n",
        "                orig_pad[..., 2][region] = fg_val\n",
        "            else:\n",
        "                orig_pad[region] = fg_val\n",
        "\n",
        "    # crop back\n",
        "    cleaned = orig_pad[unpad_img].detach().cpu().numpy()\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_path = \"/content/drive/MyDrive/img/p1_upload/RC04848/page_2.png\"\n",
        "gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "binary = (gray > 127).astype(np.uint8)\n",
        "\n",
        "cleaned_gray = apply_regions_to_original_no_blend_with_halo(\n",
        "    original_img_np=gray,\n",
        "    binary_np_img=binary,\n",
        "    min_area_black=3,\n",
        "    min_area_white=2,\n",
        "    speckle_expand_iters=1,          # try 1–2\n",
        "    speckle_expand_gray_thresh=0   # None for pure geometric; lower -> stricter\n",
        ")\n",
        "# Show\n",
        "plt.figure(figsize=(15,4))\n",
        "plt.subplot(1,3,1); plt.title(\"Original Gray\");  plt.imshow(gray, cmap='gray'); plt.axis('off')\n",
        "plt.subplot(1,3,2); plt.title(\"Binary (detect)\");plt.imshow(binary*255, cmap='gray'); plt.axis('off')\n",
        "plt.subplot(1,3,3); plt.title(\"Cleaned Gray\");   plt.imshow(cleaned_gray, cmap='gray'); plt.axis('off')\n",
        "plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv2.imwrite(\"cleaned.png\", cleaned_gray)\n",
        "files.download(\"cleaned.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emxPVz9vNWqS",
        "outputId": "8a5e491a-5316-43cf-dd55-78b5db4686a6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "# Define input and output directories\n",
        "input_dir = '/content/drive/MyDrive/img'\n",
        "output_dir = '/content/drive/MyDrive/output_img'\n",
        "\n",
        "# Phansalkar thresholding\n",
        "def phansalkar_threshold(image, window_size=31, k=0.2, R=128, p=2.0, q=6.2):\n",
        "    image = image.astype(np.float32)\n",
        "    mean = cv2.boxFilter(image, ddepth=-1, ksize=(window_size, window_size))\n",
        "    sqmean = cv2.sqrBoxFilter(image, ddepth=-1, ksize=(window_size, window_size))\n",
        "    stddev = np.sqrt(np.maximum(sqmean - mean**2, 1e-4))\n",
        "    threshold = mean * (1 + p * np.exp(-q * mean / 255) + k * ((stddev / R) - 1))\n",
        "    binary = (image > threshold).astype(np.uint8)\n",
        "    return binary\n",
        "\n",
        "# Speckle removal\n",
        "def remove_speckle(binary_np, kernel_size=5, iterations=2):\n",
        "    inv = cv2.bitwise_not(binary_np * 255)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
        "    opened = cv2.morphologyEx(inv, cv2.MORPH_OPEN, kernel, iterations=iterations)\n",
        "    return (cv2.bitwise_not(opened) > 128).astype(np.uint8)\n",
        "\n",
        "# Image processing pipeline\n",
        "def process_image(img_path):\n",
        "    gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    upscaled = cv2.resize(gray, None, fx=8, fy=8, interpolation=cv2.INTER_LANCZOS4)\n",
        "    clahe = cv2.createCLAHE(clipLimit=0.1, tileGridSize=(4, 4))\n",
        "    enhanced = clahe.apply(upscaled)\n",
        "    binary = phansalkar_threshold(enhanced)\n",
        "    binary_clean = remove_speckle(binary)\n",
        "    binary = binary_clean * 255\n",
        "    final = cv2.resize(binary, (gray.shape[1], gray.shape[0]), interpolation=cv2.INTER_AREA)\n",
        "    return final\n",
        "\n",
        "# Create output folder structure\n",
        "def create_output_structure(input_dir, output_dir):\n",
        "    for root, dirs, _ in os.walk(input_dir):\n",
        "        for dir_name in dirs:\n",
        "            rel_path = os.path.relpath(os.path.join(root, dir_name), input_dir)\n",
        "            os.makedirs(os.path.join(output_dir, rel_path), exist_ok=True)\n",
        "\n",
        "# Process and save all images\n",
        "def process_and_save_images(input_dir, output_dir):\n",
        "    create_output_structure(input_dir, output_dir)\n",
        "    for root, _, files in os.walk(input_dir):\n",
        "        for file_name in files:\n",
        "            if file_name.lower().endswith('.png'):\n",
        "                img_path = os.path.join(root, file_name)\n",
        "                try:\n",
        "                    processed_img = process_image(img_path)\n",
        "                    rel_path = os.path.relpath(img_path, input_dir)\n",
        "                    output_path = os.path.join(output_dir, rel_path)\n",
        "                    cv2.imwrite(output_path, processed_img)\n",
        "                    print(f\"Saved: {output_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed: {img_path} — {e}\")\n",
        "\n",
        "#  Run the batch processor\n",
        "process_and_save_images(input_dir, output_dir)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
