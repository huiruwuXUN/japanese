# -*- coding: utf-8 -*-
"""Kanji_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gOv3FBzcgawSKvM3dX9TjPZPbR7hxAAM
"""

!pip install -q torchvision matplotlib

import random
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
import numpy as np
import matplotlib.pyplot as plt
import os
import tarfile
from PIL import Image
from sklearn.metrics import classification_report
from tqdm.auto import tqdm
from collections import Counter
from torchvision.transforms import ToTensor, Resize, Grayscale, RandomRotation, RandomAffine
from torchvision.transforms import functional as F_transforms

seed = 42
random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed_all(seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# === uploaded: kkanji.tar and KMNIST npz loaded via torchvision ===
kanji_tar = "kkanji.tar"
kanji_folder = "kkanji"

if not os.path.exists(kanji_folder):
    os.makedirs(kanji_folder, exist_ok=True)
    with tarfile.open(kanji_tar, 'r') as tar:
        tar.extractall(path=kanji_folder)

from torchvision.datasets import KMNIST
kmnist_train = KMNIST(root='./', train=True, download=True)

# === Transforms ===
from torchvision.transforms import ToTensor, Resize, Grayscale, RandomRotation, RandomAffine

train_transform = transforms.Compose([
    RandomRotation(10),
    RandomAffine(0, translate=(0.1, 0.1)),
    Resize((64, 64)),
    Grayscale(num_output_channels=3),
    ToTensor()
])

val_transform = transforms.Compose([
    Resize((64, 64)),
    Grayscale(num_output_channels=3),
    ToTensor()
])

test_transform = val_transform

# === Static Dataset: Fixed Characters for All Epochs ===
class KanjiKanaDataset(Dataset):
    def __init__(self, max_per_class=2000):
        self.images = []

        # Load KMNIST kana
        kana_images = []
        for i in range(len(kmnist_train)):
            if len(kana_images) >= max_per_class:
                break
            img = Image.fromarray(kmnist_train.data[i].numpy())
            kana_images.append((img, 0))

        # Load Kanji from nested kkanji2/U+xxxx/*.png structure
        kanji_images = []
        kkanji2_root = os.path.join(kanji_folder, "kkanji2")
        for ucode_dir in os.listdir(kkanji2_root):
            subdir = os.path.join(kkanji2_root, ucode_dir)
            if os.path.isdir(subdir):
                for img_file in os.listdir(subdir):
                    if img_file.lower().endswith('.png'):
                        img_path = os.path.join(subdir, img_file)
                        try:
                            img = Image.open(img_path).convert("L")
                            kanji_images.append((img, 1))
                            if len(kanji_images) >= max_per_class:
                                break
                        except Exception as e:
                            print(f"Skipping {img_path}: {e}")
            if len(kanji_images) >= max_per_class:
                break

        if len(kanji_images) == 0:
            raise RuntimeError("No kanji images were found under kkanji/kkanji2/U+xxxx/")

        self.images = kana_images + kanji_images
        random.shuffle(self.images)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img, label = self.images[idx]
        return img, int(label)

# === Dynamic Resampling Dataset: Resamples a fresh set each epoch ===
class DynamicKanjiKanaDataset(Dataset):
    def __init__(self, kana_pool, kanji_root, max_per_class=2000, transform=None):
        self.kana_pool = kana_pool
        self.kanji_root = kanji_root
        self.max_per_class = max_per_class
        self.transform = transform
        self.refresh()

    def refresh(self):
        self.images = []
        kana_indices = torch.randperm(len(self.kana_pool))[:self.max_per_class]
        for i in kana_indices:
            img = Image.fromarray(self.kana_pool[i].numpy())
            self.images.append((img, 0))

        kanji_images = []
        for ucode_dir in os.listdir(self.kanji_root):
            subdir = os.path.join(self.kanji_root, ucode_dir)
            if os.path.isdir(subdir):
                for img_file in os.listdir(subdir):
                    if img_file.lower().endswith('.png'):
                        img_path = os.path.join(subdir, img_file)
                        try:
                            img = Image.open(img_path).convert("L")
                            kanji_images.append(img)
                        except: pass
        random.shuffle(kanji_images)
        for img in kanji_images[:self.max_per_class]:
            self.images.append((img, 1))

        random.shuffle(self.images)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img, label = self.images[idx]
        if self.transform:
            img = self.transform(img)
        return img, int(label)


# Create full dataset and 3-way split
full_ds = KanjiKanaDataset()
total_size = len(full_ds)
train_size = int(0.7 * total_size)
val_size = int(0.15 * total_size)
test_size = total_size - train_size - val_size

train_raw, val_raw, test_raw = torch.utils.data.random_split(
    full_ds, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42)
)



class TransformWrapper(Dataset):
    def __init__(self, dataset, transform):
        self.dataset = dataset
        self.transform = transform

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        img, label = self.dataset[idx]
        return self.transform(img), int(label)

train_ds = TransformWrapper(train_raw, train_transform)
val_ds = TransformWrapper(val_raw, val_transform)
test_ds = TransformWrapper(test_raw, test_transform)

train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)
val_dl = DataLoader(val_ds, batch_size=32)
test_dl = DataLoader(test_ds, batch_size=32)


# === Sanity check: label distribution ===
def check_label_distribution(dl, name):
    counts = Counter()
    for _, labels in dl:
        counts.update(labels.tolist())
    print(f"{name} label distribution:", counts)

check_label_distribution(train_dl, "Train")
check_label_distribution(val_dl, "Val")
check_label_distribution(test_dl, "Test")

# === Evaluate and Plot ===
def evaluate_model(model, val_dl):
    model.eval()
    y_true, y_pred = [], []
    with torch.no_grad():
        for xb, yb in val_dl:
            xb = xb.to(device)
            preds = model(xb)
            pred_labels = torch.argmax(preds, dim=1).cpu().numpy()
            y_pred.extend(pred_labels)
            y_true.extend(yb.numpy())
    print(classification_report(y_true, y_pred, target_names=["kana", "kanji"]))

# === Plot training and validation curves ===
def plot_training(history, model_name):
    epochs = len(history['train_loss'])
    x = range(1, epochs + 1)
    plt.figure(figsize=(10, 4))
    plt.subplot(1, 2, 1)
    plt.plot(x, history['train_loss'], label='Train Loss')
    plt.plot(x, history['val_loss'], label='Val Loss')
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title(f"{model_name} Loss")
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(x, history['train_acc'], label='Train Acc')
    plt.plot(x, history['val_acc'], label='Val Acc')
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.title(f"{model_name} Accuracy")
    plt.legend()
    plt.tight_layout()
    plt.show()

# === Training: Save Best Model ===
def train_model(model, train_dl, val_dl, model_name="Model", epochs=50, patience=5):
    model = model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)
    criterion = nn.CrossEntropyLoss()
    best_val_loss = float('inf')
    best_model_state = None
    no_improve_epochs = 0

    history = {"train_loss": [], "val_loss": [], "train_acc": [], "val_acc": []}

    for epoch in range(epochs):
        model.train()
        train_loss, correct, total = 0.0, 0, 0
        loop = tqdm(train_dl, desc=f"Epoch {epoch+1}/{epochs}", leave=False)
        for xb, yb in loop:
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            preds = model(xb)
            loss = criterion(preds, yb)
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * xb.size(0)
            total += yb.size(0)
            correct += (preds.argmax(1) == yb).sum().item()

            loop.set_postfix(loss=loss.item())

        scheduler.step()
        train_acc = correct / total
        train_loss /= total

        # Validation
        model.eval()
        val_loss, val_correct, val_total = 0.0, 0, 0
        with torch.no_grad():
            for xb, yb in val_dl:
                xb, yb = xb.to(device), yb.to(device)
                preds = model(xb)
                val_loss += criterion(preds, yb).item() * xb.size(0)
                val_total += yb.size(0)
                val_correct += (preds.argmax(1) == yb).sum().item()

        val_acc = val_correct / val_total
        val_loss /= val_total

        print(f"Epoch {epoch+1}/{epochs} — loss: {train_loss:.4f} — accuracy: {train_acc:.4f} — val_loss: {val_loss:.4f} — val_accuracy: {val_acc:.4f}")

        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['train_acc'].append(train_acc)
        history['val_acc'].append(val_acc)

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model_state = model.state_dict()
            no_improve_epochs = 0
            torch.save(model.state_dict(), f"best_{model_name.lower()}.pth")
        else:
            no_improve_epochs += 1
            if no_improve_epochs >= patience:
                print("Early stopping triggered.")
                break
    if model.state_dict() is not None:
      model.load_state_dict(best_model_state)
      torch.save(model.state_dict(), f"best_{model_name.lower()}.pth")

   # model.load_state_dict(best_model_state)
    plot_training(history, model_name)
    return model

# === Train with ResNet50 and DenseNet121 ===
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ResNet50
resnet = models.resnet50(pretrained=True)
resnet.fc = nn.Linear(resnet.fc.in_features, 2)
print("\nTraining ResNet50...")
resnet = train_model(resnet, train_dl, val_dl, model_name="resnet")
evaluate_model(resnet, val_dl)

# DenseNet121
densenet = models.densenet121(pretrained=True)
densenet.classifier = nn.Linear(densenet.classifier.in_features, 2)
print("\nTraining DenseNet121...")
densenet = train_model(densenet, train_dl, val_dl, model_name ="densenet")
evaluate_model(densenet, val_dl)

print("\n Final Evaluation on Test Set:")

print("\n[ResNet50 Test]")
evaluate_model(resnet, test_dl)

print("\n[DenseNet121 Test]")
evaluate_model(densenet, test_dl)

# === Dynamic Resampling Training Loop ===
def train_model_dynamic(model, kana_pool, kanji_root, epochs=10, batch_size=32, patience=7, model_name = "Model"):
    from collections import Counter
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.05)  # Start with a higher LR
    criterion = nn.CrossEntropyLoss()
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=4, verbose=True)
    best_val_loss = float('inf')
    best_model_state = None
    no_improve_epochs = 0

    for epoch in range(epochs):
        print(f"\n Epoch {epoch+1}/{epochs} — refreshing dynamic dataset...")

        dynamic_ds = DynamicKanjiKanaDataset(kana_pool=kana_pool, kanji_root=kanji_root, transform=None)
        dynamic_ds.refresh()

        # === Show label distribution after refresh ===
        label_counter = Counter([label for _, label in dynamic_ds.images])
        print(f"Label distribution after refresh: {label_counter}")

        total_size = len(dynamic_ds)
        train_size = int(0.7 * total_size)
        val_size = int(0.15 * total_size)
        test_size = total_size - train_size - val_size

        train_raw, val_raw, test_raw = torch.utils.data.random_split(
            dynamic_ds, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42 + epoch)
        )

        train_ds = TransformWrapper(train_raw, train_transform)
        val_ds = TransformWrapper(val_raw, val_transform)
        test_ds = TransformWrapper(test_raw, test_transform)

        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)
        val_dl = DataLoader(val_ds, batch_size=batch_size)
        test_dl = DataLoader(test_ds, batch_size=batch_size)

        # Train for one epoch
        model.train()
        total_loss, total_correct = 0.0, 0
        for xb, yb in tqdm(train_dl, desc=f"[Training epoch {epoch+1}]"):
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            preds = model(xb)
            loss = criterion(preds, yb)
            loss.backward()
            optimizer.step()
            total_loss += loss.item() * xb.size(0)
            total_correct += (preds.argmax(1) == yb).sum().item()

        acc = total_correct / len(train_dl.dataset)
        avg_loss = total_loss / len(train_dl.dataset)
        print(f"Train epoch {epoch+1} — loss: {avg_loss:.4f}, accuracy: {acc:.4f}")

        # Evaluate on val set
        model.eval()
        val_correct, val_total, val_loss_total, val_batches = 0, 0, 0.0, 0
        with torch.no_grad():
            for xb, yb in val_dl:
                xb, yb = xb.to(device), yb.to(device)
                preds = model(xb)
                val_loss_total += criterion(preds, yb).item()
                val_batches += 1
                val_total += yb.size(0)
                val_correct += (preds.argmax(1) == yb).sum().item()

        val_acc = val_correct / val_total
        val_loss = val_loss_total / val_batches if val_batches > 0 else 0
        print(f"Validation epoch {epoch+1} — val_loss: {val_loss:.4f}, val_accuracy: {val_acc:.4f}")
        scheduler.step(val_loss)

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model_state = model.state_dict()
            no_improve_epochs = 0
            torch.save(model.state_dict(), f"best_{model_name.lower()}.pth")
        else:
            no_improve_epochs += 1
            if no_improve_epochs >= patience:
                print("Early stopping triggered.")
                break

    if best_model_state is not None:
        model.load_state_dict(best_model_state)
        torch.save(model.state_dict(), f"best_{model_name.lower()}.pth")
    print("Final evaluation on test set:")
    evaluate_model(model, test_dl)
    return model

resnet_dynamic = models.resnet50(pretrained=True)
resnet_dynamic.fc = nn.Linear(resnet_dynamic.fc.in_features, 2)
trained_resnet_dynamic = train_model_dynamic(resnet_dynamic, kmnist_train.data, os.path.join(kanji_folder, "kkanji2"), epochs=50, model_name = "resnet_dynamic")

densenet_dynamic = models.densenet121(pretrained=True)
densenet_dynamic.classifier = nn.Linear(densenet_dynamic.classifier.in_features, 2)
trained_densenet_dynamic = train_model_dynamic(densenet_dynamic, kmnist_train.data, os.path.join(kanji_folder, "kkanji2"), epochs=50, model_name = "densenet_dynamic")

def evaluate_ensemble(model1, model2, test_dl):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model1.eval()
    model2.eval()
    y_true, y_pred = [], []
    with torch.no_grad():
        for xb, yb in test_dl:
            xb = xb.to(device)
            out1 = torch.softmax(model1(xb), dim=1)
            out2 = torch.softmax(model2(xb), dim=1)
            avg_out = (out1 + out2) / 2
            final_preds = torch.argmax(avg_out, dim=1).cpu().numpy()
            y_pred.extend(final_preds)
            y_true.extend(yb.numpy())
    print("Ensemble Classification Report:")
    print(classification_report(y_true, y_pred, target_names=["kana", "kanji"]))

evaluate_ensemble(resnet,densenet,test_dl)

#evaluate_ensemble(resnet_dynamic,densenet_dynamic,test_dl)

class InvertWrapper:
    def __call__(self, img):
        return F_transforms.invert(img)

# === Data Transforms ===
train_transform = transforms.Compose([
    transforms.RandomRotation(15),
    transforms.RandomAffine(0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.Resize((64, 64)),
    transforms.Grayscale(num_output_channels=3),
    InvertWrapper(),
    transforms.ToTensor()
])

val_transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor()
])

# === Dataset Definition ===
class FolderLabeledDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.samples = []
        self.transform = transform
        for label_name in os.listdir(root_dir):
            label_path = os.path.join(root_dir, label_name)
            if not os.path.isdir(label_path):
                continue
            label = 1 if label_name.lower() == "kanji" else 0
            for fname in sorted(os.listdir(label_path)):
                if fname.lower().endswith(".png"):
                    self.samples.append((os.path.join(label_path, fname), label))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        img = Image.open(path).convert("L")
        if self.transform:
            img = self.transform(img)
        return img, label



def fine_tune_model(model, train_dl, val_dl, epochs=20, patience=3, lr_patientce = 4, lr_factor = 0.6):
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
    criterion = nn.CrossEntropyLoss()
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_factor, patience=lr_patientce, verbose=True)
   # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5,18,32,60,110], gamma=0.5)

    best_model_state = None
    best_val_loss = float('inf')
    best_val_acc = float('inf')
    no_improve = 0

    for epoch in range(epochs):
        model.train()
        total_loss, correct = 0.0, 0
        for xb, yb in train_dl:
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            pred = model(xb)
            loss = criterion(pred, yb)
            loss.backward()
            optimizer.step()
            total_loss += loss.item() * xb.size(0)
            correct += (pred.argmax(1) == yb).sum().item()

        train_loss = total_loss / len(train_dl.dataset)
        train_acc = correct / len(train_dl.dataset)

        # Validation
        model.eval()
        val_loss, val_correct = 0.0, 0
        with torch.no_grad():
            for xb, yb in val_dl:
                xb, yb = xb.to(device), yb.to(device)
                pred = model(xb)
                val_loss += criterion(pred, yb).item() * xb.size(0)
                val_correct += (pred.argmax(1) == yb).sum().item()

        val_loss /= len(val_dl.dataset)
        val_acc = val_correct / len(val_dl.dataset)
        scheduler.step(val_loss)

        print(f"Epoch {epoch+1} - loss: {train_loss:.4f} acc: {train_acc:.4f} val_loss: {val_loss:.4f} val_acc: {val_acc:.4f} lr_after: {optimizer.param_groups[0]['lr']}")

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model_state = model.state_dict()
            no_improve = 0
        else:
            no_improve += 1
            if no_improve >= patience:
                print("Early stopping")
                break

    if best_model_state:
        model.load_state_dict(best_model_state)
        torch.save(best_model_state, f"finetuned_{model.__class__.__name__.lower()}.pth")
    return model

# === Evaluate on Test Set and Log Misclassifications ===
def evaluate_and_log_errors(model, test_dl, label_names=["nonkanji", "kanji"]):
    model.eval()
    y_true, y_pred = [], []
    misclassified = []
    with torch.no_grad():
        for xb, yb in test_dl:
            xb = xb.to(device)
            outputs = model(xb)
            preds = torch.argmax(outputs, dim=1).cpu()
            y_true.extend(yb.tolist())
            y_pred.extend(preds.tolist())

            for i in range(len(preds)):
                if preds[i] != yb[i]:
                    misclassified.append((xb[i].cpu(), yb[i], preds[i]))

    print("\nClassification Report:")
    print(classification_report(y_true, y_pred, target_names=label_names))

    # Show misclassified samples
    print(f"\n{len(misclassified)} misclassified samples:")
    fig, axes = plt.subplots(1, min(6, len(misclassified)), figsize=(15, 4))
    for i, (img_tensor, true_label, pred_label) in enumerate(misclassified[:6]):
        axes[i].imshow(img_tensor.permute(1, 2, 0).squeeze(), cmap="gray")
        axes[i].axis('off')
        axes[i].set_title(f"T:{label_names[true_label]} / P:{label_names[pred_label]}")
    plt.tight_layout()
    plt.show()

def fine_tune_model(model, train_dl, val_dl, epochs=10, patience=3):
    model_name = model.__class__.__name__
    print(f"Fine-tuning {model_name} for {epochs} epochs")
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()
    scheduler = torch.optim.lr_scheduler.OneCycleLR(
        optimizer, max_lr=0.01, steps_per_epoch=len(train_dl), epochs=epochs, pct_start=0.3, anneal_strategy='cos', final_div_factor=10.0)

    best_model_state = None
    best_val_loss = float('inf')
    no_improve = 0

    for epoch in range(epochs):
        print(f"Epoch {epoch+1}/{epochs}")
        model.train()
        total_loss, correct = 0.0, 0
        lr_tracker = []  # for visualization

        for xb, yb in train_dl:
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            pred = model(xb)
            loss = criterion(pred, yb)
            loss.backward()
            optimizer.step()
            scheduler.step()
            lr_tracker.append(optimizer.param_groups[0]['lr'])
            total_loss += loss.item() * xb.size(0)
            correct += (pred.argmax(1) == yb).sum().item()

        train_loss = total_loss / len(train_dl.dataset)
        train_acc = correct / len(train_dl.dataset)

        # Validation
        model.eval()
        val_loss, val_correct = 0.0, 0
        with torch.no_grad():
            for xb, yb in val_dl:
                xb, yb = xb.to(device), yb.to(device)
                pred = model(xb)
                val_loss += criterion(pred, yb).item() * xb.size(0)
                val_correct += (pred.argmax(1) == yb).sum().item()

        val_loss /= len(val_dl.dataset)
        val_acc = val_correct / len(val_dl.dataset)
        scheduler.step()  # Called per batch now, moved into batch loop

        print(f"Epoch {epoch+1} — Train loss: {train_loss:.4f}, acc: {train_acc:.4f} | Val loss: {val_loss:.4f}, acc: {val_acc:.4f}")

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model_state = model.state_dict()
            no_improve = 0
        else:
            no_improve += 1
            if no_improve >= patience:
                print("Early stopping")
                break

    # === Visualize LR schedule ===
    import matplotlib.pyplot as plt
    plt.plot(lr_tracker)
    plt.title("Learning Rate Schedule (OneCycle)")
    plt.xlabel("Batch")
    plt.ylabel("LR")
    plt.grid(True)
    plt.show()

    if best_model_state:
        model.load_state_dict(best_model_state)
        torch.save(best_model_state, f"finetuned_{model.__class__.__name__.lower()}.pth")
    return model

# ===Load Model (ResNet50) ===
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
resnet_sample = models.resnet50(pretrained=True)
resnet_sample.fc = nn.Linear(resnet_sample.fc.in_features, 2)
resnet_sample.load_state_dict(torch.load("/content/best_resnet.pth", map_location=device))
resnet_sample = resnet_sample.to(device)
resnet_sample = fine_tune_model(resnet_sample, train_dl, val_dl, epochs = 300, patience = 50, lr_factor=0.5)
#resnet_sample = fine_tune_model(resnet_sample, train_dl,val_dl,epochs=300, patience = 60)
evaluate_and_log_errors(resnet_sample, test_dl)

# === Load Model (DenseNet121) ===


densenet_sample = models.densenet121(pretrained=True)
densenet_sample.classifier = nn.Linear(densenet_sample.classifier.in_features, 2)
densenet_sample.load_state_dict(torch.load("/content/best_densenet.pth", map_location=device))
densenet_sample = densenet_sample.to(device)
densenet_sample = fine_tune_model(densenet_sample, train_dl, val_dl, epochs = 200, patience = 50, lr_patientce=4, lr_factor=0.6)
evaluate_and_log_errors(densenet_sample, test_dl)