{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcBun6SPeIVp",
        "outputId": "d2638a3a-a19e-4725-8513-3410a494e9a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset KMNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: /content/data\n",
              "    Split: Test"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "!pip install -q fastai torchvision --upgrade\n",
        "\n",
        "\n",
        "# Download KMNIST via torchvision (if using PyTorch)\n",
        "from torchvision import datasets\n",
        "datasets.KMNIST(root='/content/data', train=True, download=True)\n",
        "datasets.KMNIST(root='/content/data', train=False, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "metadata": {
        "id": "wvlbXEpNuLwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow"
      ],
      "metadata": {
        "id": "iNZrUKRet44k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from fastai.learner import Learner\n",
        "from fastai.metrics import accuracy\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "from torchvision.models.resnet import resnet18, ResNet, BasicBlock\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from fastai.vision import *\n",
        "from fastai import *\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import BatchSampler, DataLoader\n",
        "from fastai.data.all import DataLoaders\n",
        "import torchvision.models as models\n"
      ],
      "metadata": {
        "id": "NiwKBzRQfZSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Embedded KujuMNIST Dataset Class ===\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.datasets.utils import download_url\n",
        "from pathlib import Path\n",
        "\n",
        "class KujuMNIST_DS(Dataset):\n",
        "    urls = [\n",
        "        'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-imgs.npz',\n",
        "        'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-labels.npz',\n",
        "        'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-imgs.npz',\n",
        "        'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-labels.npz',\n",
        "    ]\n",
        "    base_filename = 'kmnist-{}-{}.npz'\n",
        "    data_filepart = 'imgs'\n",
        "    labels_filepart = 'labels'\n",
        "\n",
        "    def __init__(self, folder, train_or_test='train', download=False, num_classes=10, max_items=None, tfms=None):\n",
        "        self.root = os.path.expanduser(folder)\n",
        "        if download:\n",
        "            self.download()\n",
        "\n",
        "        self.train = (train_or_test == 'train')\n",
        "\n",
        "        self.data = np.load(os.path.join(self.root, self.base_filename.format(train_or_test, self.data_filepart)))\n",
        "        self.data = self.data['arr_0']\n",
        "        self.targets = np.load(os.path.join(self.root, self.base_filename.format(train_or_test, self.labels_filepart)))\n",
        "        self.targets = self.targets['arr_0']\n",
        "        self.c = num_classes\n",
        "        self.max_items = max_items\n",
        "        self.tfms = tfms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        cur_data = np.expand_dims(self.data[index], axis=-1)\n",
        "        if self.tfms:\n",
        "            cur_data = self.tfms(cur_data)\n",
        "        target = int(self.targets[index])\n",
        "        return cur_data, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.max_items if self.max_items else len(self.data)\n",
        "\n",
        "    def download(self):\n",
        "        Path(self.root).mkdir(parents=True, exist_ok=True)\n",
        "        for url in self.urls:\n",
        "            filename = url.rpartition('/')[-1]\n",
        "            file_path = os.path.join(self.root, filename)\n",
        "            download_url(url, root=self.root, filename=filename, md5=None)\n"
      ],
      "metadata": {
        "id": "Ho5lAwEDixZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q84feT8BeIVq"
      },
      "source": [
        "Calculate mean and std of the dataset for normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mFkSnW3eIVr",
        "outputId": "00a2ff69-b3d0-446b-c3e7-4e0df2326202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 0.1917621473589439\n",
            "Std: 0.34834283034636876\n"
          ]
        }
      ],
      "source": [
        "trn_data = np.load('/content/kmnist-train-imgs.npz')\n",
        "trn_data = trn_data['arr_0'] / 255\n",
        "data_mean = trn_data.mean()\n",
        "data_std = trn_data.std()\n",
        "print(f'Mean: {data_mean}')\n",
        "print(f'Std: {data_std}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJTi5nkNeIVr"
      },
      "source": [
        "## Prepare Datasets, DataLoaders and DataBunch\n",
        "\n",
        "Optional: A random transformations on the images in training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhJ90HOCeIVr"
      },
      "outputs": [],
      "source": [
        "default_device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "transform_train = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     #transforms.RandomAffine(degrees=7, translate=(0.1, 0.1), scale=(0.95, 1.05)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((data_mean,), (data_std,)),\n",
        "    ])\n",
        "\n",
        "transform_valid = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((data_mean,), (data_std,)),\n",
        "    ])\n",
        "\n",
        "ROOT_FOLDER = '/content/'\n",
        "\n",
        "trn_ds = KujuMNIST_DS(ROOT_FOLDER, train_or_test='train', download=False, tfms=transform_train)\n",
        "val_ds = KujuMNIST_DS(ROOT_FOLDER, train_or_test='test', download=False, tfms=transform_valid)\n",
        "\n",
        "trn_dl = DataLoader(trn_ds, batch_size=128, shuffle=True, num_workers=1, pin_memory=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=128, shuffle=True, num_workers=1, pin_memory=True)\n",
        "#databunch = DataBunch(path=ROOT_FOLDER, train_dl=trn_dl, valid_dl=val_dl, device=default_device)\n",
        "databunch = DataLoaders(trn_dl, val_dl, device=default_device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get one batch from the training DataLoader\n",
        "one_batch = next(iter(databunch.train))\n",
        "\n",
        "# The batch is a tuple: (images, labels)\n",
        "images, labels = one_batch\n",
        "\n",
        "# Get the shape of the images tensor\n",
        "image_shape = images.shape\n",
        "\n",
        "# The number of channels is the second dimension (index 1) in the shape tuple\n",
        "num_channels = image_shape[1]\n",
        "\n",
        "print(f\"Shape of one image batch: {image_shape}\")\n",
        "print(f\"Number of input channels: {num_channels}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EIr8npbqHvi",
        "outputId": "92e55401-df79-4f11-8061-258e479cb063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of one image batch: torch.Size([128, 1, 28, 28])\n",
            "Number of input channels: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-lOiwMCeIVr"
      },
      "source": [
        "MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjhXrPO6eIVr"
      },
      "outputs": [],
      "source": [
        "# dataset_transform = transforms.Compose([\n",
        "#                transforms.ToTensor(),\n",
        "#                transforms.Normalize((0.1307,), (0.3081,))\n",
        "#            ])\n",
        "\n",
        "# mnist_trn_ds = MNIST('/content/', train=True, download=False, transform=dataset_transform)\n",
        "# mnist_val_ds = MNIST('/content/', train=False, download=False, transform=dataset_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vArooOiYeIVs"
      },
      "source": [
        "## VGG Model\n",
        "\n",
        "Based on - https://github.com/kkweon/mnist-competition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tt7oZPreIVs"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "class VGG(nn.Module):\n",
        "    \"\"\"\n",
        "    Based on - https://github.com/kkweon/mnist-competition\n",
        "    \"\"\"\n",
        "    def two_conv_pool(self, in_channels, f1, f2):\n",
        "        s = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, f1, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(f1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(f1, f2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(f2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        for m in s.children():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "        return s\n",
        "\n",
        "    def three_conv_pool(self,in_channels, f1, f2, f3):\n",
        "        s = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, f1, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(f1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(f1, f2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(f2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(f2, f3, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(f3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        for m in s.children():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "        return s\n",
        "\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG, self).__init__()\n",
        "        self.l1 = self.two_conv_pool(1, 64, 64)\n",
        "        self.l2 = self.two_conv_pool(64, 128, 128)\n",
        "        self.l3 = self.three_conv_pool(128, 256, 256, 256)\n",
        "        self.l4 = self.three_conv_pool(256, 256, 256, 256)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l1(x)\n",
        "        x = self.l2(x)\n",
        "        x = self.l3(x)\n",
        "        x = self.l4(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRY0ObGzeIVs"
      },
      "outputs": [],
      "source": [
        "vgg_model_with_norm = models.vgg16_bn(pretrained=True)\n",
        "vgg_model_with_norm.classifier[6] = nn.Linear(4096, 10)\n",
        "learn = Learner(databunch, VGG(), metrics=accuracy, loss_func = nn.CrossEntropyLoss(reduction='mean'))\n",
        "# learn.load('vgg_model_with_norm')\n",
        "# print('Model was loaded')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NZB5H0shqv2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyJgwWtoeIVs",
        "outputId": "2da6b70f-2fb8-480a-8b27-4f3c671b1200",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0.08840512484312057, 0.25744563341140747, 0.921999990940094, '00:18']\n"
          ]
        }
      ],
      "source": [
        "learn.fit(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbJDTziaeIVs"
      },
      "source": [
        "## ResNet Model\n",
        "\n",
        "Based on - https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKfmEIFyeIVs"
      },
      "outputs": [],
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class MyResNet(nn.Module):\n",
        "    # Based on PyTorch ResNet-18\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=10, zero_init_residual=False):\n",
        "        super(MyResNet, self).__init__()\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.Linear(512 * block.expansion, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "#         import pdb; pdb.set_trace()\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBFYmkZVeIVt",
        "outputId": "0c1880e8-c110-41f7-b320-53c2b3312f53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model was loaded\n"
          ]
        }
      ],
      "source": [
        "learn = Learner(databunch, MyResNet(BasicBlock, [2, 2, 2, 2]), metrics=accuracy)\n",
        "learn.load('resnet_model_with_norm')\n",
        "print('Model was loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YzTuiT0eIVt",
        "outputId": "456f3755-d96e-4733-a2f6-6bd15a6b7448"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Total time: 02:20 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>0.037798</th>\n",
              "    <th>0.115575</th>\n",
              "    <th>0.969600</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "learn.fit(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhnRZdG7eIVt"
      },
      "source": [
        "## Ensemble of VGG and ResNet-18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrXxrDtNeIVt"
      },
      "outputs": [],
      "source": [
        "class VGG_ResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG_ResNet, self).__init__()\n",
        "        self.vgg = VGG()\n",
        "        self.resnet = MyResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        vgg_out = self.vgg(x)\n",
        "        resnet_out = self.resnet(x)\n",
        "        out = (vgg_out + resnet_out) / 2\n",
        "        return out\n",
        "\n",
        "def vgg_resnet_load_model(learner, vgg_name, resnet_name):\n",
        "        device = learner.data.device\n",
        "        vgg_state = torch.load(learner.path/learner.model_dir/f'{vgg_name}.pth', map_location=device)\n",
        "        learner.model.vgg.load_state_dict(vgg_state['model'], strict=True)\n",
        "\n",
        "        resnet_state = torch.load(learner.path/learner.model_dir/f'{resnet_name}.pth', map_location=device)\n",
        "        learner.model.resnet.load_state_dict(resnet_state['model'], strict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCKAlGPSeIVt",
        "outputId": "9429f12c-de9c-4253-affe-48051f15267f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model was loaded\n"
          ]
        }
      ],
      "source": [
        "learn = Learner(databunch, VGG_ResNet(), metrics=accuracy)\n",
        "# vgg_resnet_load_model(learn, vgg_name, resnet_name)\n",
        "learn.load('vgg_resnet_model_with_norm')\n",
        "print('Model was loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOlnTuS6eIVt",
        "outputId": "8aac770b-c68e-492e-ba85-d46f3822b04f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Total time: 03:21 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>0.015457</th>\n",
              "    <th>0.092744</th>\n",
              "    <th>0.989000</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "learn.fit(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy7uwH-peIVt"
      },
      "source": [
        "## Capsule Network\n",
        "\n",
        "Taken from - https://github.com/higgsfield/Capsule-Network-Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HdDzJZYeIVt"
      },
      "outputs": [],
      "source": [
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=256, kernel_size=9):\n",
        "        super(ConvLayer, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
        "                               out_channels=out_channels,\n",
        "                               kernel_size=kernel_size,\n",
        "                               stride=1\n",
        "                             )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.conv(x))\n",
        "\n",
        "class PrimaryCaps(nn.Module):\n",
        "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32, kernel_size=9):\n",
        "        super(PrimaryCaps, self).__init__()\n",
        "\n",
        "        self.capsules = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=0)\n",
        "                          for _ in range(num_capsules)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = [capsule(x) for capsule in self.capsules]\n",
        "        u = torch.stack(u, dim=1)\n",
        "        u = u.view(x.size(0), 32 * 6 * 6, -1)\n",
        "        return self.squash(u)\n",
        "\n",
        "    def squash(self, input_tensor):\n",
        "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
        "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
        "        return output_tensor\n",
        "\n",
        "class DigitCaps(nn.Module):\n",
        "    def __init__(self, num_capsules=10, num_routes=32 * 6 * 6, in_channels=8, out_channels=16):\n",
        "        super(DigitCaps, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.num_routes = num_routes\n",
        "        self.num_capsules = num_capsules\n",
        "\n",
        "        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
        "\n",
        "        W = torch.cat([self.W] * batch_size, dim=0)\n",
        "        u_hat = torch.matmul(W, x)\n",
        "\n",
        "        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n",
        "\n",
        "        b_ij = b_ij.to(default_device)\n",
        "\n",
        "        num_iterations = 3\n",
        "        for iteration in range(num_iterations):\n",
        "            c_ij = F.softmax(b_ij)\n",
        "            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
        "\n",
        "            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
        "            v_j = self.squash(s_j)\n",
        "\n",
        "            if iteration < num_iterations - 1:\n",
        "                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n",
        "                b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n",
        "\n",
        "        return v_j.squeeze(1)\n",
        "\n",
        "    def squash(self, input_tensor):\n",
        "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
        "        output_tensor = squared_norm *  input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
        "        return output_tensor\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.reconstraction_layers = nn.Sequential(\n",
        "            nn.Linear(16 * 10, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 784),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, data):\n",
        "        classes = torch.sqrt((x ** 2).sum(2))\n",
        "        classes = F.softmax(classes)\n",
        "\n",
        "        _, max_length_indices = classes.max(dim=1)\n",
        "        masked = Variable(torch.eye(10))\n",
        "\n",
        "        masked = masked.to(default_device)\n",
        "        masked = masked.index_select(dim=0, index=max_length_indices.squeeze(1).data)\n",
        "\n",
        "        reconstructions = self.reconstraction_layers((x * masked[:, :, None, None]).view(x.size(0), -1))\n",
        "        reconstructions = reconstructions.view(-1, 1, 28, 28)\n",
        "\n",
        "        return reconstructions, masked\n",
        "\n",
        "\n",
        "def caps_loss(inputs, targets):\n",
        "    targets = torch.eye(10).index_select(dim=0, index=targets.cpu()).to(default_device)\n",
        "    data, output, reconstructions, masked = inputs\n",
        "    return margin_loss(output, targets) + reconstruction_loss(data, reconstructions)\n",
        "\n",
        "def margin_loss(x, labels, size_average=True):\n",
        "    batch_size = x.size(0)\n",
        "\n",
        "    v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True))\n",
        "    left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
        "    right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
        "\n",
        "    loss = labels * left + 0.5 * (1.0 - labels) * right\n",
        "    loss = loss.sum(dim=1).mean()\n",
        "\n",
        "    return loss\n",
        "\n",
        "def reconstruction_loss(data, reconstructions):\n",
        "    loss = F.mse_loss(reconstructions.view(reconstructions.size(0), -1), data.view(reconstructions.size(0), -1))\n",
        "    return loss * 0.0005\n",
        "\n",
        "def caps_accuracy(inputs, targs):\n",
        "    masked = inputs[-1]\n",
        "    predictions = np.argmax(masked.data.cpu().numpy(), 1)\n",
        "    return torch.tensor((predictions == targs.cpu().numpy()).mean())\n",
        "\n",
        "\n",
        "class CapsNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CapsNet, self).__init__()\n",
        "        self.conv_layer = ConvLayer()\n",
        "        self.primary_capsules = PrimaryCaps()\n",
        "        self.digit_capsules = DigitCaps()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, data):\n",
        "        output = self.digit_capsules(self.primary_capsules(self.conv_layer(data)))\n",
        "        reconstructions, masked = self.decoder(output, data)\n",
        "        return data, output, reconstructions, masked\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40y2RzCjeIVt",
        "outputId": "8fc5faa1-8d2e-45df-aaaa-33a2623105f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model was loaded\n"
          ]
        }
      ],
      "source": [
        "learn = Learner(databunch, CapsNet(), metrics=caps_accuracy, loss_func=caps_loss)\n",
        "# vgg_resnet_load_model(learn, vgg_name, resnet_name)\n",
        "learn.load('caps_net_model_with_norm')\n",
        "print('Model was loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hE3Yj9lXeIVu",
        "outputId": "3f353698-df2f-4797-f581-b3d47dfe222a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Total time: 06:35 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>caps_accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>0.006563</th>\n",
              "    <th>0.071374</th>\n",
              "    <th>0.976700</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "learn.fit(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-B4CQLseIVu"
      },
      "source": [
        "## Ensemble of VGG and Capsule Network\n",
        "\n",
        "Results are worse than VGG-ResNet Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNwmfuRYeIVu"
      },
      "outputs": [],
      "source": [
        "class VGG_Caps(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG_Caps, self).__init__()\n",
        "        self.vgg = VGG()\n",
        "        caps_model = CapsNet()\n",
        "        self.capsnet = caps_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        vgg_out = self.vgg(x)\n",
        "        capsnet_out = self.capsnet(x)\n",
        "        return vgg_out, capsnet_out\n",
        "\n",
        "\n",
        "def vgg_capsnet_load_model(learner, vgg_name, caps_name):\n",
        "        device = learner.data.device\n",
        "        vgg_state = torch.load(learner.path/learner.model_dir/f'{vgg_name}.pth', map_location=device)\n",
        "        learner.model.vgg.load_state_dict(vgg_state['model'], strict=True)\n",
        "\n",
        "        capsnet_state = torch.load(learner.path/learner.model_dir/f'{caps_name}.pth', map_location=device)\n",
        "        learner.model.capsnet.load_state_dict(capsnet_state['model'], strict=True)\n",
        "\n",
        "def vgg_caps_accuracy(outputs, targs):\n",
        "    caps_outputs = outputs[1][-1]\n",
        "    vgg_outputs = outputs[0]\n",
        "    batch_size = targs.size(0)\n",
        "\n",
        "    caps_outputs = F.softmax(caps_outputs, dim=1)\n",
        "\n",
        "    final_preds = (caps_outputs + vgg_outputs) / 2\n",
        "    final_preds = final_preds.argmax(dim=-1).view(batch_size,-1)\n",
        "\n",
        "    targs = targs.view(batch_size,-1)\n",
        "    return (final_preds==targs).float().mean()\n",
        "\n",
        "def vgg_caps_loss(inputs, targets):\n",
        "    vgg_loss = torch.functional.F.nll_loss(inputs[0], targets)\n",
        "    return caps_loss(inputs[1], targets) + vgg_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBrdpiV2eIVu"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-u7bnMaeIVu"
      },
      "outputs": [],
      "source": [
        "learn = Learner(databunch, VGG_Caps(), metrics=vgg_caps_accuracy, loss_func=vgg_caps_loss)\n",
        "vgg_capsnet_load_model(learn, 'vgg_model_with_norm', 'caps_net_model_with_norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ppuBIWmxeIVu",
        "outputId": "90b9553c-5e71-4bd4-b00e-ce2f785d1735"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Total time: 07:42 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>vgg_caps_accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>0.022337</th>\n",
              "    <th>0.150881</th>\n",
              "    <th>0.986300</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:88: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "learn.fit(1)\n",
        "# learn.save('vgg_resnet_model_with_norm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebIpmlL3eIVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "596745e3-7d07-4a84-8ff3-b1820d0c0979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples, 10000 test samples\n",
            "Epoch 0: Learning Rate = 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.7525 - loss: 0.7769 - val_accuracy: 0.8777 - val_loss: 0.4095\n",
            "Epoch 2/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.1893 - val_accuracy: 0.9151 - val_loss: 0.2926\n",
            "Epoch 3/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9598 - loss: 0.1328 - val_accuracy: 0.9255 - val_loss: 0.2649\n",
            "Epoch 4/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9675 - loss: 0.1069 - val_accuracy: 0.9246 - val_loss: 0.2690\n",
            "Epoch 5/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9724 - loss: 0.0915 - val_accuracy: 0.9367 - val_loss: 0.2341\n",
            "Epoch 6/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9756 - loss: 0.0792 - val_accuracy: 0.9413 - val_loss: 0.2304\n",
            "Epoch 7/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9777 - loss: 0.0732 - val_accuracy: 0.9451 - val_loss: 0.2220\n",
            "Epoch 8/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.0648 - val_accuracy: 0.9460 - val_loss: 0.2282\n",
            "Epoch 9/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.0618 - val_accuracy: 0.9448 - val_loss: 0.2288\n",
            "Epoch 10/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9813 - loss: 0.0581 - val_accuracy: 0.9453 - val_loss: 0.2212\n",
            "Epoch 11/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9839 - loss: 0.0521 - val_accuracy: 0.9476 - val_loss: 0.2225\n",
            "Epoch 12/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9838 - loss: 0.0511 - val_accuracy: 0.9486 - val_loss: 0.2102\n",
            "Epoch 13/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0478 - val_accuracy: 0.9500 - val_loss: 0.2382\n",
            "Epoch 14/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.0455 - val_accuracy: 0.9515 - val_loss: 0.2356\n",
            "Epoch 15/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0436 - val_accuracy: 0.9484 - val_loss: 0.2556\n",
            "Epoch 16/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0472 - val_accuracy: 0.9501 - val_loss: 0.2280\n",
            "Epoch 17/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0427 - val_accuracy: 0.9521 - val_loss: 0.2633\n",
            "Epoch 18/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0388 - val_accuracy: 0.9475 - val_loss: 0.2359\n",
            "Epoch 19/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9878 - loss: 0.0415 - val_accuracy: 0.9535 - val_loss: 0.2181\n",
            "Epoch 20/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0403 - val_accuracy: 0.9484 - val_loss: 0.2612\n",
            "Epoch 21/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.0398 - val_accuracy: 0.9525 - val_loss: 0.2417\n",
            "Epoch 22/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0393 - val_accuracy: 0.9511 - val_loss: 0.2226\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "Train loss: 0.012839799746870995\n",
            "Train accuracy: 0.9975833296775818\n",
            "Test loss: 0.21017910540103912\n",
            "Test accuracy: 0.9485999941825867\n"
          ]
        }
      ],
      "source": [
        "# Based on MNIST CNN from Keras' examples: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py (MIT License)\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "# Set a common seed value\n",
        "SEED_VALUE = 42\n",
        "\n",
        "# 1. Set Python's general random seed\n",
        "random.seed(SEED_VALUE)\n",
        "\n",
        "# 2. Set NumPy's random seed\n",
        "np.random.seed(SEED_VALUE)\n",
        "\n",
        "# 3. Set TensorFlow's random seeds\n",
        "# Set the global seed\n",
        "tf.random.set_seed(SEED_VALUE)\n",
        "# Set the seed for reproducible operations (if using older TensorFlow versions)\n",
        "# tf.compat.v1.set_random_seed(SEED_VALUE) # Uncomment if needed for older TF\n",
        "\n",
        "# 4. Set PyTorch's random seeds\n",
        "# Note: Ensure PyTorch is imported if you are using it elsewhere\n",
        "if 'torch' in globals() and torch.cuda.is_available():\n",
        "    # Set CUDA seed for GPU operations\n",
        "    torch.cuda.manual_seed_all(SEED_VALUE)\n",
        "elif 'torch' in globals():\n",
        "     # Set CPU seed\n",
        "    torch.manual_seed(SEED_VALUE)\n",
        "\n",
        "\n",
        "# 5. Set environment variables for TensorFlow/Keras and CuDNN reproducibility\n",
        "# These might help with certain operations, though their effectiveness can vary\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1' # For newer TensorFlow\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1' # For newer TensorFlow with CuDNN\n",
        "\n",
        "# For older TensorFlow/CuDNN\n",
        "# os.environ['TF_ENABLE_DETERMINISTIC_OPS'] = '1' # Uncomment if needed\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '' # Uncomment to force CPU, helps with reproducibility\n",
        "\n",
        "# --- END SUGGESTED CHANGE ---\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "def load(f):\n",
        "    return np.load(f)['arr_0']\n",
        "\n",
        "# Load the data\n",
        "x_train = load('/content/kmnist-train-imgs.npz')\n",
        "x_test = load('/content/kmnist-test-imgs.npz')\n",
        "y_train = load('/content/kmnist-train-labels.npz')\n",
        "y_test = load('/content/kmnist-test-labels.npz')\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('{} train samples, {} test samples'.format(len(x_train), len(x_test)))\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# --- SUGGESTED CHANGE ---\n",
        "# Import the LearningRateScheduler callback\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.optimizers import Adadelta\n",
        "\n",
        "# Define a learning rate schedule function\n",
        "# This function takes the epoch index as input and returns the learning rate\n",
        "def step_decay(epoch):\n",
        "    initial_lrate = 1.0 # Adadelta default learning rate is 1.0\n",
        "    drop = 0.5\n",
        "    epochs_drop = 10.0\n",
        "    lrate = initial_lrate * (drop ** np.floor((epoch) / epochs_drop))\n",
        "    print(f\"Epoch {epoch}: Learning Rate = {lrate}\") # Optional: Print the learning rate for monitoring\n",
        "    return lrate\n",
        "\n",
        "# Instantiate the LearningRateScheduler callback\n",
        "lrate_scheduler = LearningRateScheduler(step_decay)\n",
        "\n",
        "# Instantiate the optimizer (Adadelta in this case) - learning rate will be set by the scheduler\n",
        "optimizer = Adadelta(learning_rate=step_decay(0)) # Set initial learning rate\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=optimizer, # Use the optimizer instance\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# --- SUGGESTED CHANGE ---\n",
        "# Import the EarlyStopping callback\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Instantiate the EarlyStopping callback\n",
        "# Monitor validation loss ('val_loss')\n",
        "# Stop training if 'val_loss' does not improve for 10 consecutive epochs (patience=10)\n",
        "# Consider an improvement if the change is at least 0.001 (min_delta=0.001)\n",
        "# Restore the model weights from the epoch with the best 'val_loss' (restore_best_weights=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=10,\n",
        "                               min_delta=0.001,\n",
        "                               restore_best_weights=True,\n",
        "                               verbose=1) # Add verbose=1 to see when early stopping triggers\n",
        "\n",
        "# Pass the EarlyStopping callback to the fit method in a list\n",
        "callbacks_list = [early_stopping]\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=callbacks_list) # Pass the list of callbacks\n",
        "# --- END SUGGESTED CHANGE ---\n",
        "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
        "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Train loss:', train_score[0])\n",
        "print('Train accuracy:', train_score[1])\n",
        "print('Test loss:', test_score[0])\n",
        "print('Test accuracy:', test_score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kNN with neighbors=4 benchmark for Kuzushiji-MNIST\n",
        "# Acheives 92.10% test accuracy\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "\n",
        "def load(f):\n",
        "    return np.load(f)['arr_0']\n",
        "\n",
        "# Load the data\n",
        "x_train = load('kmnist-train-imgs.npz')\n",
        "x_test = load('kmnist-test-imgs.npz')\n",
        "y_train = load('kmnist-train-labels.npz')\n",
        "y_test = load('kmnist-test-labels.npz')\n",
        "\n",
        "# Flatten images\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "clf = KNeighborsClassifier(n_neighbors=4, weights='distance', n_jobs=-1)\n",
        "print('Fitting', clf)\n",
        "clf.fit(x_train, y_train)\n",
        "print('Evaluating', clf)\n",
        "\n",
        "test_score = clf.score(x_test, y_test)\n",
        "print('Test accuracy:', test_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z23_CzIBvvJJ",
        "outputId": "a4f847d1-6bf7-45d5-bff8-f1e736b502ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')\n",
            "Evaluating KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')\n",
            "Test accuracy: 0.921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rl1RRMEbvv28"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}