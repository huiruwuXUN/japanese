{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose of the Code\n",
    "This Python script processes low-quality images to highlight and extract bright (white-ish) areas, then saves the result.\n",
    "\n",
    "#### Main Processing Steps\n",
    "1. Load the Image\n",
    "Reads an input image file (e.g., 1.png).\n",
    "\n",
    "2. Noise Reduction & Grayscale Conversion\n",
    "Applies Gaussian blur to reduce noise, then converts the image to grayscale.\n",
    "\n",
    "3. Evaluate Noise Level\n",
    "Calculates the standard deviation of the grayscale image as an indicator of how noisy the image is.\n",
    "\n",
    "4. Adaptive Thresholding\n",
    "Based on the noise level, the script adjusts thresholds (qerr1, qerr2) used to determine which pixels should be turned white.\n",
    "\n",
    "5. Color Histogram Calculation\n",
    "Computes histograms for red, green, and blue channels to find the most frequent color in each channel.\n",
    "\n",
    "6. White Pixel Detection (Color Distance)\n",
    "Compares each pixel’s color to the average color. If it’s close enough (within qerr1 or qerr2), the pixel is changed to white. This is done in two passes for stronger emphasis.\n",
    "\n",
    "7. Binarization of Bright Areas\n",
    "Uses thresholding to create a mask of bright regions, and forces those regions to white.\n",
    "\n",
    "8. Save the Result\n",
    "Saves the processed image in a folder called processed_images, with a filename like processed_1.png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Thresholds -> qerr1: 34, qerr2: 157, Std Dev: 23.85\n",
      "Detected color mode -> R: 231, G: 216, B: 190\n",
      "Processed image saved: processed_images/processed_1.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def create_output_directory():\n",
    "    output_dir = \"processed_images\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    return output_dir\n",
    "\n",
    "def load_image(filename):\n",
    "    image = cv2.imread(filename)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Error: Cannot open or read image file '{filename}'. Please check file path and integrity.\")\n",
    "    return image\n",
    "\n",
    "def adaptive_threshold(image):\n",
    "    \"\"\"\n",
    "    画質の悪い画像にも対応するため、適応的なしきい値を導入。\n",
    "    - 画像のノイズが多い場合、しきい値を緩くする。\n",
    "    - 明るい部分の判定を二値化で補助。\n",
    "    \n",
    "    To handle low-quality images, an adaptive thresholding approach is introduced.\n",
    "    - When the image contains a lot of noise, the threshold is relaxed.\n",
    "    - Bright areas are additionally identified using binarization.\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)  # Remove noise\n",
    "    gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 画像全体の標準偏差を計算（ノイズレベルの指標）\n",
    "    # Calculate the standard deviation of the entire image (as an indicator of noise level)\n",
    "    std_dev = np.std(gray)\n",
    "    \n",
    "    # 標準偏差に応じてしきい値を調整\n",
    "    # Adjust the threshold based on the standard deviation\n",
    "    qerr1 = int(30 + (std_dev / 5))  # Increase the threshold as the standard deviation increases\n",
    "    qerr2 = int(150 + (std_dev / 3))\n",
    "\n",
    "    print(f\"Adaptive Thresholds -> qerr1: {qerr1}, qerr2: {qerr2}, Std Dev: {std_dev:.2f}\")\n",
    "\n",
    "    # 明るい部分を二値化で取得\n",
    "    # Extract bright areas using binarization\n",
    "    _, bright_mask = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 色ヒストグラム計算\n",
    "    # Calculate color histogram\n",
    "    r_arr, g_arr, b_arr = np.zeros(256, dtype=int), np.zeros(256, dtype=int), np.zeros(256, dtype=int)\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            b, g, r = image[i, j]\n",
    "            r_arr[r] += 1\n",
    "            g_arr[g] += 1\n",
    "            b_arr[b] += 1\n",
    "    \n",
    "    r_mean = np.argmax(r_arr)\n",
    "    g_mean = np.argmax(g_arr)\n",
    "    b_mean = np.argmax(b_arr)\n",
    "\n",
    "    print(f\"Detected color mode -> R: {r_mean}, G: {g_mean}, B: {b_mean}\")\n",
    "\n",
    "    new_image = image.copy()\n",
    "\n",
    "    # 明るさの距離が `qerr1` 以下なら白にする\n",
    "    # Set to white if the brightness difference is less than or equal to `qerr1`\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            b, g, r = new_image[i, j]\n",
    "            err = math.sqrt((b - b_mean) ** 2 + (g - g_mean) ** 2 + (r - r_mean) ** 2)\n",
    "            if err < qerr1:\n",
    "                new_image[i, j] = np.array([255, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    # 明るさの距離が `qerr2` 以下なら白にする（強調）\n",
    "    # Set to white if the brightness difference is less than or equal to `qerr2` (emphasized)\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            b, g, r = new_image[i, j]\n",
    "            err = math.sqrt((b - 255) ** 2 + (g - 255) ** 2 + (r - 255) ** 2)\n",
    "            if err < qerr2:\n",
    "                new_image[i, j] = np.array([255, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    # 二値化した明るい部分を適用\n",
    "    # Apply the binarized bright areas\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if bright_mask[i, j] == 255:  # Force bright areas to be white\n",
    "                new_image[i, j] = np.array([255, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    return new_image\n",
    "\n",
    "def process_image(filename):\n",
    "    try:\n",
    "        output_dir = create_output_directory()\n",
    "        image = load_image(filename)\n",
    "        processed_image = adaptive_threshold(image)\n",
    "        output_path = os.path.join(output_dir, \"processed_\" + os.path.basename(filename))\n",
    "        \n",
    "        if not cv2.imwrite(output_path, processed_image):\n",
    "            raise IOError(f\"Failed to save processed image to {output_path}\")\n",
    "        \n",
    "        print(f\"Processed image saved: {output_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image '{filename}': {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"1.png\" \n",
    "    process_image(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Thresholds -> qerr1: 37, qerr2: 162, Std Dev: 36.33\n",
      "Detected color mode -> R: 224, G: 212, B: 183\n",
      "Saved: processed_images/processed_J257..png\n",
      "Adaptive Thresholds -> qerr1: 36, qerr2: 161, Std Dev: 34.80\n",
      "Detected color mode -> R: 228, G: 215, B: 191\n",
      "Saved: processed_images/processed_J241..png\n",
      "Adaptive Thresholds -> qerr1: 37, qerr2: 162, Std Dev: 36.54\n",
      "Detected color mode -> R: 244, G: 215, B: 187\n",
      "Saved: processed_images/processed_J236..png\n",
      "Adaptive Thresholds -> qerr1: 35, qerr2: 159, Std Dev: 28.22\n",
      "Detected color mode -> R: 244, G: 211, B: 183\n",
      "Saved: processed_images/processed_J237..png\n",
      "Adaptive Thresholds -> qerr1: 37, qerr2: 161, Std Dev: 35.52\n",
      "Detected color mode -> R: 219, G: 206, B: 175\n",
      "Saved: processed_images/processed_J295..png\n",
      "Adaptive Thresholds -> qerr1: 40, qerr2: 166, Std Dev: 50.14\n",
      "Detected color mode -> R: 225, G: 213, B: 184\n",
      "Saved: processed_images/processed_J240..png\n",
      "Adaptive Thresholds -> qerr1: 38, qerr2: 164, Std Dev: 44.82\n",
      "Detected color mode -> R: 218, G: 206, B: 178\n",
      "Saved: processed_images/processed_J305..png\n",
      "Adaptive Thresholds -> qerr1: 36, qerr2: 160, Std Dev: 31.14\n",
      "Detected color mode -> R: 228, G: 217, B: 188\n",
      "Saved: processed_images/processed_J11.png\n",
      "Adaptive Thresholds -> qerr1: 39, qerr2: 165, Std Dev: 47.63\n",
      "Detected color mode -> R: 223, G: 209, B: 179\n",
      "Saved: processed_images/processed_J318..png\n",
      "Adaptive Thresholds -> qerr1: 37, qerr2: 162, Std Dev: 38.08\n",
      "Detected color mode -> R: 225, G: 214, B: 185\n",
      "Saved: processed_images/processed_J4.png\n",
      "Adaptive Thresholds -> qerr1: 37, qerr2: 162, Std Dev: 38.15\n",
      "Detected color mode -> R: 224, G: 213, B: 184\n",
      "Saved: processed_images/processed_J5.png\n",
      "Adaptive Thresholds -> qerr1: 38, qerr2: 164, Std Dev: 43.97\n",
      "Detected color mode -> R: 223, G: 211, B: 178\n",
      "Saved: processed_images/processed_J271..png\n",
      "Adaptive Thresholds -> qerr1: 37, qerr2: 162, Std Dev: 37.18\n",
      "Detected color mode -> R: 223, G: 211, B: 182\n",
      "Saved: processed_images/processed_J7.png\n",
      "Adaptive Thresholds -> qerr1: 38, qerr2: 163, Std Dev: 41.07\n",
      "Detected color mode -> R: 220, G: 209, B: 182\n",
      "Saved: processed_images/processed_J251..png\n",
      "Adaptive Thresholds -> qerr1: 36, qerr2: 160, Std Dev: 30.31\n",
      "Detected color mode -> R: 234, G: 230, B: 214\n",
      "Saved: processed_images/processed_J104 cropped..png\n",
      "Adaptive Thresholds -> qerr1: 36, qerr2: 160, Std Dev: 30.77\n",
      "Detected color mode -> R: 227, G: 216, B: 188\n",
      "Saved: processed_images/processed_J6.png\n",
      "Adaptive Thresholds -> qerr1: 34, qerr2: 158, Std Dev: 24.01\n",
      "Detected color mode -> R: 235, G: 221, B: 194\n",
      "Saved: processed_images/processed_J2.png\n",
      "Adaptive Thresholds -> qerr1: 37, qerr2: 162, Std Dev: 37.54\n",
      "Detected color mode -> R: 223, G: 212, B: 182\n",
      "Saved: processed_images/processed_J285..png\n",
      "Adaptive Thresholds -> qerr1: 40, qerr2: 167, Std Dev: 52.93\n",
      "Detected color mode -> R: 224, G: 214, B: 185\n",
      "Saved: processed_images/processed_J3.png\n",
      "Adaptive Thresholds -> qerr1: 33, qerr2: 156, Std Dev: 18.98\n",
      "Detected color mode -> R: 249, G: 245, B: 229\n",
      "Saved: processed_images/processed_J335..png\n",
      "Adaptive Thresholds -> qerr1: 34, qerr2: 157, Std Dev: 23.85\n",
      "Detected color mode -> R: 231, G: 216, B: 190\n",
      "Saved: processed_images/processed_J1.png\n",
      "Adaptive Thresholds -> qerr1: 36, qerr2: 160, Std Dev: 31.54\n",
      "Detected color mode -> R: 221, G: 213, B: 184\n",
      "Saved: processed_images/processed_J289..png\n",
      "Adaptive Thresholds -> qerr1: 38, qerr2: 163, Std Dev: 41.74\n",
      "Detected color mode -> R: 232, G: 230, B: 210\n",
      "Saved: processed_images/processed_J110.png\n",
      "Adaptive Thresholds -> qerr1: 39, qerr2: 165, Std Dev: 45.65\n",
      "Detected color mode -> R: 220, G: 209, B: 179\n",
      "Saved: processed_images/processed_J273..png\n",
      "Adaptive Thresholds -> qerr1: 35, qerr2: 159, Std Dev: 27.80\n",
      "Detected color mode -> R: 217, G: 203, B: 167\n",
      "Saved: processed_images/processed_J336..png\n",
      "Adaptive Thresholds -> qerr1: 36, qerr2: 161, Std Dev: 33.14\n",
      "Detected color mode -> R: 217, G: 215, B: 199\n",
      "Saved: processed_images/processed_J109.png\n",
      "Adaptive Thresholds -> qerr1: 41, qerr2: 168, Std Dev: 55.40\n",
      "Detected color mode -> R: 244, G: 213, B: 183\n",
      "Saved: processed_images/processed_J265..png\n",
      "Adaptive Thresholds -> qerr1: 36, qerr2: 160, Std Dev: 30.95\n",
      "Detected color mode -> R: 229, G: 227, B: 206\n",
      "Saved: processed_images/processed_J108.png\n",
      "Adaptive Thresholds -> qerr1: 34, qerr2: 158, Std Dev: 24.89\n",
      "Detected color mode -> R: 228, G: 217, B: 189\n",
      "Saved: processed_images/processed_J249..png\n",
      "Adaptive Thresholds -> qerr1: 38, qerr2: 164, Std Dev: 42.78\n",
      "Detected color mode -> R: 222, G: 209, B: 176\n",
      "Saved: processed_images/processed_J286..png\n",
      "Adaptive Thresholds -> qerr1: 44, qerr2: 174, Std Dev: 73.92\n",
      "Detected color mode -> R: 225, G: 214, B: 185\n",
      "Saved: processed_images/processed_J253..png\n",
      "Adaptive Thresholds -> qerr1: 40, qerr2: 166, Std Dev: 50.44\n",
      "Detected color mode -> R: 225, G: 214, B: 184\n",
      "Saved: processed_images/processed_J252..png\n",
      "Adaptive Thresholds -> qerr1: 35, qerr2: 158, Std Dev: 25.47\n",
      "Detected color mode -> R: 214, G: 213, B: 188\n",
      "Saved: processed_images/processed_J182..png\n",
      "Adaptive Thresholds -> qerr1: 37, qerr2: 162, Std Dev: 38.57\n",
      "Detected color mode -> R: 209, G: 202, B: 174\n",
      "Saved: processed_images/processed_J301..png\n",
      "Adaptive Thresholds -> qerr1: 38, qerr2: 164, Std Dev: 42.30\n",
      "Detected color mode -> R: 226, G: 215, B: 187\n",
      "Saved: processed_images/processed_J244..png\n",
      "Adaptive Thresholds -> qerr1: 35, qerr2: 159, Std Dev: 29.91\n",
      "Detected color mode -> R: 215, G: 206, B: 178\n",
      "Saved: processed_images/processed_J268..png\n",
      "Adaptive Thresholds -> qerr1: 38, qerr2: 164, Std Dev: 42.80\n",
      "Detected color mode -> R: 211, G: 188, B: 142\n",
      "Saved: processed_images/processed_J8.png\n",
      "Adaptive Thresholds -> qerr1: 35, qerr2: 159, Std Dev: 28.14\n",
      "Detected color mode -> R: 227, G: 216, B: 186\n",
      "Saved: processed_images/processed_J248..png\n",
      "Adaptive Thresholds -> qerr1: 35, qerr2: 159, Std Dev: 29.07\n",
      "Detected color mode -> R: 215, G: 203, B: 174\n",
      "Saved: processed_images/processed_J296..png\n",
      "Adaptive Thresholds -> qerr1: 37, qerr2: 161, Std Dev: 35.61\n",
      "Detected color mode -> R: 225, G: 217, B: 188\n",
      "Saved: processed_images/processed_J238..png\n",
      "Adaptive Thresholds -> qerr1: 39, qerr2: 165, Std Dev: 45.55\n",
      "Detected color mode -> R: 239, G: 205, B: 177\n",
      "Saved: processed_images/processed_J275..png\n",
      "Adaptive Thresholds -> qerr1: 35, qerr2: 159, Std Dev: 29.51\n",
      "Detected color mode -> R: 233, G: 230, B: 214\n",
      "Saved: processed_images/processed_J104 full..png\n",
      "Adaptive Thresholds -> qerr1: 36, qerr2: 160, Std Dev: 32.47\n",
      "Detected color mode -> R: 226, G: 215, B: 185\n",
      "Saved: processed_images/processed_J259..png\n",
      "Adaptive Thresholds -> qerr1: 34, qerr2: 157, Std Dev: 23.85\n",
      "Detected color mode -> R: 231, G: 216, B: 190\n",
      "Saved: processed_images/processed_1.png\n",
      "Adaptive Thresholds -> qerr1: 36, qerr2: 160, Std Dev: 31.90\n",
      "Detected color mode -> R: 227, G: 216, B: 189\n",
      "Saved: processed_images/processed_J254..png\n",
      "Adaptive Thresholds -> qerr1: 35, qerr2: 158, Std Dev: 26.79\n",
      "Detected color mode -> R: 220, G: 217, B: 200\n",
      "Saved: processed_images/processed_J184..png\n",
      "Adaptive Thresholds -> qerr1: 38, qerr2: 164, Std Dev: 43.92\n",
      "Detected color mode -> R: 219, G: 206, B: 176\n",
      "Saved: processed_images/processed_J307..png\n",
      "Adaptive Thresholds -> qerr1: 39, qerr2: 166, Std Dev: 48.26\n",
      "Detected color mode -> R: 225, G: 217, B: 190\n",
      "Saved: processed_images/processed_J242..png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def create_output_directory():\n",
    "    output_dir = \"processed_images\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    return output_dir\n",
    "\n",
    "def load_image(filename):\n",
    "    image = cv2.imread(filename)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Error: Cannot open or read image file '{filename}'. Please check file path and integrity.\")\n",
    "    return image\n",
    "\n",
    "def adaptive_threshold(image):\n",
    "    height, width, _ = image.shape\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    std_dev = np.std(gray)\n",
    "    qerr1 = int(30 + (std_dev / 5))\n",
    "    qerr2 = int(150 + (std_dev / 3))\n",
    "\n",
    "    print(f\"Adaptive Thresholds -> qerr1: {qerr1}, qerr2: {qerr2}, Std Dev: {std_dev:.2f}\")\n",
    "\n",
    "    _, bright_mask = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    r_arr, g_arr, b_arr = np.zeros(256, dtype=int), np.zeros(256, dtype=int), np.zeros(256, dtype=int)\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            b, g, r = image[i, j]\n",
    "            r_arr[r] += 1\n",
    "            g_arr[g] += 1\n",
    "            b_arr[b] += 1\n",
    "\n",
    "    r_mean = np.argmax(r_arr)\n",
    "    g_mean = np.argmax(g_arr)\n",
    "    b_mean = np.argmax(b_arr)\n",
    "\n",
    "    print(f\"Detected color mode -> R: {r_mean}, G: {g_mean}, B: {b_mean}\")\n",
    "\n",
    "    new_image = image.copy()\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            b, g, r = new_image[i, j]\n",
    "            err = math.sqrt((b - b_mean) ** 2 + (g - g_mean) ** 2 + (r - r_mean) ** 2)\n",
    "            if err < qerr1:\n",
    "                new_image[i, j] = np.array([255, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            b, g, r = new_image[i, j]\n",
    "            err = math.sqrt((b - 255) ** 2 + (g - 255) ** 2 + (r - 255) ** 2)\n",
    "            if err < qerr2:\n",
    "                new_image[i, j] = np.array([255, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if bright_mask[i, j] == 255:\n",
    "                new_image[i, j] = np.array([255, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    return new_image\n",
    "\n",
    "def process_all_images(input_dir=\"images\", output_dir=\"processed_images\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    supported_extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")\n",
    "\n",
    "    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(supported_extensions)]\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No image files found in '{input_dir}'\")\n",
    "        return\n",
    "\n",
    "    for filename in image_files:\n",
    "        try:\n",
    "            filepath = os.path.join(input_dir, filename)\n",
    "            image = load_image(filepath)\n",
    "            processed_image = adaptive_threshold(image)\n",
    "            output_path = os.path.join(output_dir, f\"processed_{filename}\")\n",
    "            cv2.imwrite(output_path, processed_image)\n",
    "            print(f\"Saved: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_images()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
